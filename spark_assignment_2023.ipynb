{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 03 (Individual) - Due Thursday, November 16 at Midnight\n",
    "\n",
    "*Objectives*: Use Spark to process and perform basic analysis on non-relational data, including its DataFrame and SQL interfaces.\n",
    "\n",
    "*Grading criteria*: The tasks should all be completed, and questions should all be answered with Python code, SQL queries, shell commands, and markdown cells.  The notebook itself should be completely reproducible (using AWS EC2 instance based on the provided AMI) from start to finish; another person should be able to use the code to obtain the same results as yours.  Note that you will receive no more than partial credit if you do not add text/markdown cells explaining your thinking when appropriate.\n",
    "\n",
    "\n",
    "*Deadline*: Thursday, November 16 at Midnight  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Setup\n",
    "\n",
    "Begin by setting up Spark and fetching the project data.  \n",
    "\n",
    "**Note**: you may want to use a larger EC2 instance type than normal.  This project was prepared using a `t2.xlarge` instance.  Just remember that the larger the instance, the higher the per-hour charge, so be sure to remember to shut your instance down when you're done, as always.\n",
    "\n",
    "### About the data\n",
    "\n",
    "We will use JSON data from Twitter; we saw an example of this in class.  It should parse cleanly, allowing you to focus on analysis.\n",
    "\n",
    "This data was gathered using GWU Libraries' [data sets](https://tweetsets.library.gwu.edu/datasets) during a game of the MLB World Series featuring the Los Angeles Dodgers and Houston Astros.  This first file tells you a little bit about how it was gathered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First make sure you are working from the right working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/notebooks/Indi Assignment\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This below file provides context and detail information on the files we are going to work with\n",
    "#### in this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-07 21:49:22--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611-README.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.128.32, 54.231.192.200, 16.182.64.32, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.128.32|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1920 (1.9K) [text/plain]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611-README.txt’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>]   1.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-11-07 21:49:22 (95.4 MB/s) - ‘9670f3399f774789b7c3e18975d25611-README.txt’ saved [1920/1920]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611-README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an export created with Social Feed Manager.\n",
      "\n",
      "EXPORT INFORMATION\n",
      "Selected seeds: All seeds\n",
      "Export id: 9670f3399f774789b7c3e18975d25611\n",
      "Export type: twitter_filter\n",
      "Format: Full JSON\n",
      "Export completed:  Oct. 30, 2017, 11:21:04 p.m. EDT\n",
      "Deduplicate: No\n",
      "\n",
      "COLLECTION INFORMATION\n",
      "Collection name: test set for world series\n",
      "Collection id: 34e3f7460b5c4df09d64a1e61fd81238\n",
      "Collection set: mlb-test (collection set id d6e8c27b1bc942e78790aa55a82b3a7a)\n",
      "Harvest type: Twitter filter\n",
      "Collection description: running for just one hour, just for fun.\n",
      "\n",
      "Harvest options:\n",
      "Media: No\n",
      "Web resources: No\n",
      "\n",
      "Seeds:\n",
      "* Track: dodgers,astros - Active\n",
      "\n",
      "Change log:\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 30, 2017, 10:59:56 p.m. EDT by dchud:\n",
      "* is_active: \"True\" changed to \"False\"\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 30, 2017, 10:58:51 p.m. EDT by dchud:\n",
      "* is_on: \"True\" changed to \"False\"\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 29, 2017, 8:01:24 p.m. EDT by dchud:\n",
      "* is_on: \"False\" changed to \"True\"\n",
      "\n",
      "Change to Track: dodgers,astros (seed) on Oct. 29, 2017, 8:01:21 p.m. EDT by dchud:\n",
      "* token: \"blank\" changed to \"{\"track\": \"dodgers,astros\"}\"\n",
      "* is_active: \"blank\" changed to \"True\"\n",
      "\n",
      "Change to test set for world series (collection) on Oct. 29, 2017, 8:01:06 p.m. EDT by dchud:\n",
      "* credential: \"blank\" changed to \"dchud's twitter credential\"\n",
      "* harvest_type: \"blank\" changed to \"twitter_filter\"\n",
      "* is_on: \"blank\" changed to \"False\"\n",
      "* end_date: \"blank\" changed to \"Oct. 31, 2017, 8:00:38 p.m. EDT\"\n",
      "* description: \"blank\" changed to \"running for just one hour, just for fun.\"\n",
      "* collection_set: \"blank\" changed to \"mlb-test\"\n",
      "* is_active: \"blank\" changed to \"True\"\n",
      "* visibility: \"blank\" changed to \"default\"\n",
      "* harvest_options: \"blank\" changed to \"{\"media\": false, \"web_resources\": false}\"\n",
      "* name: \"blank\" changed to \"test set for world series\"\n",
      "\n",
      "\n",
      "Created on Oct. 30, 2017, 11:21:04 p.m. EDT\n"
     ]
    }
   ],
   "source": [
    "!cat 9670f3399f774789b7c3e18975d25611-README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important pieces in that metadata are:\n",
    "\n",
    " * It tracked tweets that mentioned \"dodgers\" or \"astros\".  Every item in this set should refer to one or the other, or both.\n",
    " * This data was not deduplicated; we may see individual items more than once.\n",
    " * Data was collected between October 29 and October 30.  Game 5 of the Series was played during this time.\n",
    " \n",
    "You should not need to know anything about baseball to complete this assignment.\n",
    "\n",
    "**Please note**: sometimes social media data contains offensive material.  This data set has not been filtered; if you do come across something inappropriate, please do your best to ignore it if you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data\n",
    "\n",
    "The following files are available:\n",
    "\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_003.json\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_006.json\n",
    " \n",
    "### Q1.1 - Upload the above files to your instance using `wget`.  Verify the file sizes using the command line. \n",
    "\n",
    "Each file should contain exactly 100,000 tweets.  \n",
    "\n",
    "*Note*: you are required to use all files.  It will be easier to process more data if you use a larger EC2 instance type, as suggested above.  Use the exact same set of files throughout the assignment.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-07 21:50:26--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_003.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.162.165, 52.216.214.144, 52.217.132.200, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.162.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 595711407 (568M) [application/json]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611_003.json’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>] 568.11M  66.1MB/s    in 8.8s    \n",
      "\n",
      "2023-11-07 21:50:35 (64.3 MB/s) - ‘9670f3399f774789b7c3e18975d25611_003.json’ saved [595711407/595711407]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_003.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-07 21:51:01--  https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_006.json\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.170.160, 52.217.225.240, 54.231.139.8, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.170.160|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 545081593 (520M) [application/json]\n",
      "Saving to: ‘9670f3399f774789b7c3e18975d25611_006.json’\n",
      "\n",
      "9670f3399f774789b7c 100%[===================>] 519.83M  58.8MB/s    in 8.5s    \n",
      "\n",
      "2023-11-07 21:51:09 (61.2 MB/s) - ‘9670f3399f774789b7c3e18975d25611_006.json’ saved [545081593/545081593]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_006.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the files have exactly 100,000 tweets using the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 9670f3399f774789b7c3e18975d25611_003.json\n"
     ]
    }
   ],
   "source": [
    "!wc -l 9670f3399f774789b7c3e18975d25611_003.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 9670f3399f774789b7c3e18975d25611_006.json\n"
     ]
    }
   ],
   "source": [
    "!wc -l 9670f3399f774789b7c3e18975d25611_006.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your reference, here is the text of one Tweet, randomly selected from one of these files.  You might wish to study its structure and refer to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat *.json | shuf -n 1 > example-tweet.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"quote_count\": 0,\n",
      "  \"contributors\": null,\n",
      "  \"truncated\": false,\n",
      "  \"text\": \"No argument that a glaring disparity has been identified. https://t.co/KPUPOaU7HP\",\n",
      "  \"is_quote_status\": true,\n",
      "  \"in_reply_to_status_id\": null,\n",
      "  \"reply_count\": 0,\n",
      "  \"id\": 924827857280536576,\n",
      "  \"favorite_count\": 0,\n",
      "  \"entities\": {\n",
      "    \"user_mentions\": [],\n",
      "    \"symbols\": [],\n",
      "    \"hashtags\": [],\n",
      "    \"urls\": [\n",
      "      {\n",
      "        \"url\": \"https://t.co/KPUPOaU7HP\",\n",
      "        \"indices\": [\n",
      "          58,\n",
      "          81\n",
      "        ],\n",
      "        \"expanded_url\": \"https://twitter.com/jaysonst/status/924826054790995968\",\n",
      "        \"display_url\": \"twitter.com/jaysonst/statu\\u2026\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"quoted_status_id\": 924826054790995968,\n",
      "  \"retweeted\": false,\n",
      "  \"coordinates\": null,\n",
      "  \"timestamp_ms\": \"1509331118303\",\n",
      "  \"quoted_status\": {\n",
      "    \"quote_count\": 32,\n",
      "    \"contributors\": null,\n",
      "    \"truncated\": false,\n",
      "    \"text\": \"Astros bullpen has now allowed 30 ER in this postseason (in 48 IP). Dodgers bullpen has allowed 10 (in 47.1). No further comment required\",\n",
      "    \"is_quote_status\": false,\n",
      "    \"in_reply_to_status_id\": null,\n",
      "    \"reply_count\": 17,\n",
      "    \"id\": 924826054790995968,\n",
      "    \"favorite_count\": 188,\n",
      "    \"source\": \"<a href=\\\"http://twitter.com/#!/download/ipad\\\" rel=\\\"nofollow\\\">Twitter for iPad</a>\",\n",
      "    \"retweeted\": false,\n",
      "    \"coordinates\": null,\n",
      "    \"entities\": {\n",
      "      \"user_mentions\": [],\n",
      "      \"symbols\": [],\n",
      "      \"hashtags\": [],\n",
      "      \"urls\": []\n",
      "    },\n",
      "    \"in_reply_to_screen_name\": null,\n",
      "    \"id_str\": \"924826054790995968\",\n",
      "    \"retweet_count\": 175,\n",
      "    \"in_reply_to_user_id\": null,\n",
      "    \"favorited\": false,\n",
      "    \"user\": {\n",
      "      \"follow_request_sent\": null,\n",
      "      \"profile_use_background_image\": true,\n",
      "      \"default_profile_image\": false,\n",
      "      \"id\": 19735580,\n",
      "      \"default_profile\": true,\n",
      "      \"verified\": true,\n",
      "      \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1177914959/Twitter_pic_normal.jpg\",\n",
      "      \"profile_sidebar_fill_color\": \"DDEEF6\",\n",
      "      \"profile_text_color\": \"333333\",\n",
      "      \"followers_count\": 545814,\n",
      "      \"profile_sidebar_border_color\": \"C0DEED\",\n",
      "      \"id_str\": \"19735580\",\n",
      "      \"profile_background_color\": \"C0DEED\",\n",
      "      \"listed_count\": 11140,\n",
      "      \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "      \"utc_offset\": -14400,\n",
      "      \"statuses_count\": 27107,\n",
      "      \"description\": \"Former senior writer, http://ESPN.com. Finally graduated! But still grateful for invention of baseball, Twitter & trivia.\",\n",
      "      \"friends_count\": 2863,\n",
      "      \"location\": \"Philadelphia\",\n",
      "      \"profile_link_color\": \"1DA1F2\",\n",
      "      \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1177914959/Twitter_pic_normal.jpg\",\n",
      "      \"following\": null,\n",
      "      \"geo_enabled\": true,\n",
      "      \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "      \"name\": \"Jayson Stark\",\n",
      "      \"lang\": \"en\",\n",
      "      \"profile_background_tile\": false,\n",
      "      \"favourites_count\": 8801,\n",
      "      \"screen_name\": \"jaysonst\",\n",
      "      \"notifications\": null,\n",
      "      \"url\": \"http://espn.go.com/espn/columnists/archive/_/name/jayson-stark\",\n",
      "      \"created_at\": \"Thu Jan 29 21:27:26 +0000 2009\",\n",
      "      \"contributors_enabled\": false,\n",
      "      \"time_zone\": \"Eastern Time (US & Canada)\",\n",
      "      \"protected\": false,\n",
      "      \"translator_type\": \"none\",\n",
      "      \"is_translator\": false\n",
      "    },\n",
      "    \"geo\": null,\n",
      "    \"in_reply_to_user_id_str\": null,\n",
      "    \"lang\": \"en\",\n",
      "    \"created_at\": \"Mon Oct 30 02:31:28 +0000 2017\",\n",
      "    \"filter_level\": \"low\",\n",
      "    \"in_reply_to_status_id_str\": null,\n",
      "    \"place\": null\n",
      "  },\n",
      "  \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\",\n",
      "  \"in_reply_to_screen_name\": null,\n",
      "  \"id_str\": \"924827857280536576\",\n",
      "  \"display_text_range\": [\n",
      "    0,\n",
      "    57\n",
      "  ],\n",
      "  \"retweet_count\": 0,\n",
      "  \"in_reply_to_user_id\": null,\n",
      "  \"favorited\": false,\n",
      "  \"user\": {\n",
      "    \"follow_request_sent\": null,\n",
      "    \"profile_use_background_image\": true,\n",
      "    \"default_profile_image\": false,\n",
      "    \"id\": 52250148,\n",
      "    \"default_profile\": false,\n",
      "    \"verified\": false,\n",
      "    \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/923588114223902721/5j7h9-FQ_normal.jpg\",\n",
      "    \"profile_sidebar_fill_color\": \"C0DFEC\",\n",
      "    \"profile_text_color\": \"333333\",\n",
      "    \"followers_count\": 272,\n",
      "    \"profile_sidebar_border_color\": \"A8C7F7\",\n",
      "    \"id_str\": \"52250148\",\n",
      "    \"profile_background_color\": \"022330\",\n",
      "    \"listed_count\": 11,\n",
      "    \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/83545342/TexasFlag1.jpg\",\n",
      "    \"utc_offset\": -18000,\n",
      "    \"statuses_count\": 14690,\n",
      "    \"description\": \"Houstonian living his best Texpat life in ChiBeria. Follow for aggrieved Astros tweets and potent potables.\",\n",
      "    \"friends_count\": 498,\n",
      "    \"location\": \"Chicago, Illinois\",\n",
      "    \"profile_link_color\": \"0084B4\",\n",
      "    \"profile_image_url\": \"http://pbs.twimg.com/profile_images/923588114223902721/5j7h9-FQ_normal.jpg\",\n",
      "    \"following\": null,\n",
      "    \"geo_enabled\": true,\n",
      "    \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/52250148/1362593036\",\n",
      "    \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/83545342/TexasFlag1.jpg\",\n",
      "    \"name\": \"alias Terry Frisk\",\n",
      "    \"lang\": \"en\",\n",
      "    \"profile_background_tile\": false,\n",
      "    \"favourites_count\": 6623,\n",
      "    \"screen_name\": \"TexanAlex\",\n",
      "    \"notifications\": null,\n",
      "    \"url\": null,\n",
      "    \"created_at\": \"Tue Jun 30 00:52:58 +0000 2009\",\n",
      "    \"contributors_enabled\": false,\n",
      "    \"time_zone\": \"Central Time (US & Canada)\",\n",
      "    \"protected\": false,\n",
      "    \"translator_type\": \"none\",\n",
      "    \"is_translator\": false\n",
      "  },\n",
      "  \"geo\": null,\n",
      "  \"in_reply_to_user_id_str\": null,\n",
      "  \"possibly_sensitive\": false,\n",
      "  \"lang\": \"en\",\n",
      "  \"created_at\": \"Mon Oct 30 02:38:38 +0000 2017\",\n",
      "  \"quoted_status_id_str\": \"924826054790995968\",\n",
      "  \"filter_level\": \"low\",\n",
      "  \"in_reply_to_status_id_str\": null,\n",
      "  \"place\": {\n",
      "    \"full_name\": \"Hinsdale, IL\",\n",
      "    \"url\": \"https://api.twitter.com/1.1/geo/id/a2e9665d39e55b17.json\",\n",
      "    \"country\": \"United States\",\n",
      "    \"place_type\": \"city\",\n",
      "    \"bounding_box\": {\n",
      "      \"type\": \"Polygon\",\n",
      "      \"coordinates\": [\n",
      "        [\n",
      "          [\n",
      "            -87.952677,\n",
      "            41.763847\n",
      "          ],\n",
      "          [\n",
      "            -87.952677,\n",
      "            41.828954\n",
      "          ],\n",
      "          [\n",
      "            -87.899883,\n",
      "            41.828954\n",
      "          ],\n",
      "          [\n",
      "            -87.899883,\n",
      "            41.763847\n",
      "          ]\n",
      "        ]\n",
      "      ]\n",
      "    },\n",
      "    \"country_code\": \"US\",\n",
      "    \"attributes\": {},\n",
      "    \"id\": \"a2e9665d39e55b17\",\n",
      "    \"name\": \"Hinsdale\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(json.load(open(\"example-tweet.json\")), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find several key elements in this example; the text, time, and language of the tweet, whether it was a reply to another user, the user's screen name along with their primary language and other account information like creation date, follower/friend/tweet counts, and perhaps their location.  \n",
    "If there are hashtags, user mentions, or urls present in their tweet, they will be present in the `entities` section; these are not present in every tweet.  If this is a retweet, you will see the original tweet and its information nested within."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 - Start up Spark, and verify the file sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our normal startup sequence here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SPARK_HOME'] = '/usr/local/lib/spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/17 03:52:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkContext(appName='project-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-40-162.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>project-03</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=project-03>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/spark/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlc = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f6d3ddcad90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f example-tweet.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are removing the exmpale tweet here to avoid the confusion while taking the tweet count below and also for further questions to not duplicate this exmaple as it is the data that is already existing\n",
    "in the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/17 03:53:11 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "tweets = sqlc.read.json(\"*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that Spark has loaded the same number of tweets you saw before:\n",
    "\n",
    "**Answer** Yes, spark has also loaded the same number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.24 ms, sys: 286 µs, total: 5.53 ms\n",
      "Wall time: 2.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that word count of both JSON files combined is 200000 and it's same as using command line above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see exactly the same number of tweets in Spark that you saw on the command line? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Comparing DataFrames and Spark SQL\n",
    "\n",
    "For the next three questions, we will look at operations using both DataFrames and SQL queries. Note that `tweets` is already a DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To issue SQL queries, we need to register a table based on `tweets`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all well and good, but how well did schema inference work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.createOrReplaceTempView(\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 - Which 6 languages are most commonly used in tweets?  Verify your result by executing it with both the dataframe and with SQL.\n",
    "\n",
    "Hint: for the dataframe, use `groupBy`, `count`, and `orderBy`.  See the documentation at https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html for details on these and other functions.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|lang|count(lang)|\n",
      "+----+-----------+\n",
      "|  en|     173906|\n",
      "|  es|      15666|\n",
      "| und|       7579|\n",
      "|  in|        483|\n",
      "|  pt|        479|\n",
      "|  fr|        435|\n",
      "+----+-----------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets.groupBy(\"lang\").agg({\"lang\": \"count\"}).orderBy(\"count(lang)\", ascending=False).select('lang',\"count(lang)\").show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|lang|count(lang)|\n",
      "+----+-----------+\n",
      "|  en|     173906|\n",
      "|  es|      15666|\n",
      "| und|       7579|\n",
      "|  in|        483|\n",
      "|  pt|        479|\n",
      "|  fr|        435|\n",
      "+----+-----------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT lang, count(lang) \n",
    "    FROM tweets\n",
    "    group by lang\n",
    "    ORDER BY count(lang) DESC\n",
    "\"\"\").show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen above, 'en' is the most common language used in tweets with 173906 times used and also the top are as seen in the outputs above using both dataframe and SQL methods. We have taken count of language count(lang) here to get the aggregate of users using that particular language and order by descending to get the top languages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 - Which 5 time zones are most common among users?  Verify your result with both the dataframe and SQL.\n",
    "\n",
    "*Note*: for this question, you may leave NULL values present in your results, as a way to help you understand what data is present and what is missing.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|           time_zone|count(time_zone)|\n",
      "+--------------------+----------------+\n",
      "|Pacific Time (US ...|           35816|\n",
      "|Central Time (US ...|           32031|\n",
      "|Eastern Time (US ...|           17780|\n",
      "|             Arizona|            5199|\n",
      "|Mountain Time (US...|            4700|\n",
      "+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets.select('user.time_zone').groupBy(\"time_zone\").agg({\"time_zone\": \"count\"}).orderBy(\"count(time_zone)\", ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|           time_zone|count(user.time_zone)|\n",
      "+--------------------+---------------------+\n",
      "|Pacific Time (US ...|                35816|\n",
      "|Central Time (US ...|                32031|\n",
      "|Eastern Time (US ...|                17780|\n",
      "|             Arizona|                 5199|\n",
      "|Mountain Time (US...|                 4700|\n",
      "+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.time_zone,count(user.time_zone)\n",
    "    FROM tweets\n",
    "    group by user.time_zone\n",
    "    ORDER BY count(user.time_zone) DESC\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Five most common time zones among users start with Pacific time and end with Mountain Time as seen in the above outputs/results from both dataframe and SQL. We have taken count of time_zone to get the number of users in that partiular time zone and order by count(time_zone) in descending order to get the top time_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 - How many tweets mention the Dodgers?  How many mention the Astros?  How many mention both?\n",
    "\n",
    "You may use either the dataframe or SQL to answer.  Explain why you have chosen that approach.\n",
    "\n",
    "Hint:  you will want to look at the value of the `text` field.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(text)|\n",
      "+-----------+\n",
      "|      78522|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT count(text)\n",
    "    FROM tweets\n",
    "    WHERE LOWER(text) LIKE '%dodgers%'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(text)|\n",
      "+-----------+\n",
      "|     127041|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT count(text)\n",
    "    FROM tweets\n",
    "    WHERE LOWER(text) LIKE '%astros%'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(text)|\n",
      "+-----------+\n",
      "|      24016|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT count(text)\n",
    "    FROM tweets\n",
    "    WHERE LOWER(text) LIKE '%astros%'\n",
    "    AND LOWER(text) LIKE '%dodgers%'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have used SQL approach to get the tweets that mention Astros or Dodgers or Both because I felt it is easier method for this question to use SQL. I have converted all text into lower case to eliminate case issues while looking for astros or dodgers.\n",
    "##### Astros are mentioned 127041 times, Dodgers are mentioned 78522 times and the tweets that contain both of them are 24016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - More complex queries\n",
    "\n",
    "For this section, you may choose to use dataframe queries or SQL.  If you wish, you may verify results by using both, as in Part 2, but this is not required for this section.\n",
    "\n",
    "### Q3.1 - Team mentions by location\n",
    "\n",
    "In which users' locations are the Astros and the Dodgers being mentioned the most?  Consider each team separately, one at a time.  Discuss your findings. Do not count null time_zones or location.\n",
    "\n",
    "Hint:  you may use either the time zones or user-specified locations for this question.\n",
    "\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|           time_zone|count(user.time_zone)|\n",
      "+--------------------+---------------------+\n",
      "|Central Time (US ...|                25187|\n",
      "|Pacific Time (US ...|                17165|\n",
      "|Eastern Time (US ...|                12430|\n",
      "|Mountain Time (US...|                 3392|\n",
      "|             Arizona|                 2257|\n",
      "|Atlantic Time (Ca...|                 1700|\n",
      "|             Caracas|                 1420|\n",
      "|               Quito|                 1339|\n",
      "|              Hawaii|                 1107|\n",
      "|         Mexico City|                 1055|\n",
      "|     America/Chicago|                  738|\n",
      "|              Alaska|                  628|\n",
      "|     Central America|                  431|\n",
      "|              Bogota|                  312|\n",
      "|            Brasilia|                  272|\n",
      "| America/Los_Angeles|                  253|\n",
      "|           Monterrey|                  233|\n",
      "|              London|                  215|\n",
      "|    America/New_York|                  209|\n",
      "|            Santiago|                  154|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.time_zone, count(user.time_zone)\n",
    "    FROM tweets\n",
    "    WHERE LOWER(text) LIKE '%astros%'\n",
    "    GROUP BY user.time_zone\n",
    "    ORDER BY count(user.time_zone) DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|           time_zone|count(user.time_zone)|\n",
      "+--------------------+---------------------+\n",
      "|Pacific Time (US ...|                19435|\n",
      "|Central Time (US ...|                 6699|\n",
      "|Eastern Time (US ...|                 5960|\n",
      "|             Arizona|                 3026|\n",
      "|Mountain Time (US...|                 1407|\n",
      "|             Caracas|                 1217|\n",
      "|         Mexico City|                 1043|\n",
      "|              Alaska|                  926|\n",
      "|               Quito|                  853|\n",
      "|Atlantic Time (Ca...|                  816|\n",
      "|              Hawaii|                  692|\n",
      "| America/Los_Angeles|                  335|\n",
      "|             Tijuana|                  262|\n",
      "|     Central America|                  254|\n",
      "|     America/Chicago|                  174|\n",
      "|              Bogota|                  168|\n",
      "|               Tokyo|                  155|\n",
      "|            Brasilia|                  145|\n",
      "|              London|                  138|\n",
      "|           Monterrey|                  135|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.time_zone, count(user.time_zone)\n",
    "    FROM tweets\n",
    "    WHERE LOWER(text) LIKE '%dodgers%'\n",
    "    GROUP BY user.time_zone\n",
    "    ORDER BY count(user.time_zone) DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|           time_zone|count(user.time_zone)|\n",
      "+--------------------+---------------------+\n",
      "|Pacific Time (US ...|                 4286|\n",
      "|Central Time (US ...|                 3193|\n",
      "|Eastern Time (US ...|                 2508|\n",
      "|Mountain Time (US...|                  570|\n",
      "|             Arizona|                  554|\n",
      "|         Mexico City|                  511|\n",
      "|             Caracas|                  508|\n",
      "|Atlantic Time (Ca...|                  339|\n",
      "|               Quito|                  334|\n",
      "|              Hawaii|                  216|\n",
      "|     Central America|                  137|\n",
      "|              Alaska|                  136|\n",
      "|              Bogota|                  105|\n",
      "| America/Los_Angeles|                   89|\n",
      "|     America/Chicago|                   87|\n",
      "|              London|                   75|\n",
      "|            Brasilia|                   64|\n",
      "|           Monterrey|                   60|\n",
      "|    America/New_York|                   51|\n",
      "|             Tijuana|                   43|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.time_zone, count(user.time_zone)\n",
    "    FROM tweets\n",
    "    WHERE LOWER(text) LIKE '%dodgers%' AND LOWER(text) LIKE '%astros%'\n",
    "    GROUP BY user.time_zone\n",
    "    ORDER BY count(user.time_zone) DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using SQL we found the team mentions astros and dodgers separately as well as combined using time zone. Converted text into lower case to eliminate the case sensitive nature and also used count(time_zone) to get the aggregate of time zone users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 - Which Twitter users are being replied to the most?\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "Hint: use the top-level `in_reply_to_screen_name` for this.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------------------------+\n",
      "|in_reply_to_screen_name|count(in_reply_to_screen_name)|\n",
      "+-----------------------+------------------------------+\n",
      "|                 astros|                          2061|\n",
      "|                Dodgers|                          1569|\n",
      "|                    MLB|                           464|\n",
      "|               MLBONFOX|                           113|\n",
      "|          stephenasmith|                           109|\n",
      "|          DodgerInsider|                            92|\n",
      "|          DodgersNation|                            92|\n",
      "|           JoseAltuve27|                            59|\n",
      "|                 feSOUL|                            57|\n",
      "|             JohnLegere|                            55|\n",
      "|          Nick_Offerman|                            54|\n",
      "|              adevaldes|                            53|\n",
      "|                ABREG_1|                            51|\n",
      "|           ESPN_Beisbol|                            50|\n",
      "|                trvisXX|                            49|\n",
      "|              MayorOfLA|                            46|\n",
      "|              el_yuly10|                            45|\n",
      "|        JustinVerlander|                            45|\n",
      "|                   Buck|                            43|\n",
      "|         Cody_Bellinger|                            42|\n",
      "+-----------------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT in_reply_to_screen_name, count(in_reply_to_screen_name)\n",
    "    FROM tweets\n",
    "    GROUP BY in_reply_to_screen_name\n",
    "    ORDER BY count(in_reply_to_screen_name) DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken the count of in_reply_to_screen_name to get the aggregate count and grouping it by the same column. Order by the count(in_reply_to_screen_name) in descending order to get the top most \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3 - Which 12 verified users have the most followers?  Which 12 unverified users have the most followers?\n",
    "\n",
    "Provide both the screen names (screen_name) and follower counts (followers_count) for each.\n",
    "Verified users -- use verified == 't'\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------+--------+\n",
      "|   screen_name|max(user.followers_count)|verified|\n",
      "+--------------+-------------------------+--------+\n",
      "|       Reuters|                 18937529|    true|\n",
      "|       FoxNews|                 16272836|    true|\n",
      "|           ABC|                 12551437|    true|\n",
      "|washingtonpost|                 11417638|    true|\n",
      "|           MLB|                  7841255|    true|\n",
      "|           NPR|                  7289492|    true|\n",
      "|   BillSimmons|                  6000106|    true|\n",
      "|     Residente|                  5856019|    true|\n",
      "|       NBCNews|                  5442705|    true|\n",
      "|    JohnLegere|                  4630104|    true|\n",
      "|     ANCALERTS|                  4453229|    true|\n",
      "|       Milenio|                  4007212|    true|\n",
      "+--------------+-------------------------+--------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.screen_name, max(user.followers_count), user.verified\n",
    "    FROM tweets\n",
    "    WHERE user.verified == true\n",
    "    GROUP BY user.screen_name, user.verified\n",
    "    ORDER BY max(user.followers_count) DESC\n",
    "\"\"\").show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuters have the highest followers count in verified users while Milenio is in the 12th place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------------+--------+\n",
      "|    screen_name|max(user.followers_count)|verified|\n",
      "+---------------+-------------------------+--------+\n",
      "|Daminous_Purity|                   998742|   false|\n",
      "|        chochos|                   833669|   false|\n",
      "|  el_carabobeno|                   725952|   false|\n",
      "|       PAMsLOvE|                   712254|   false|\n",
      "| mlbtraderumors|                   659851|   false|\n",
      "|        jilevin|                   568341|   false|\n",
      "|    sun_das_ill|                   559669|   false|\n",
      "|   DiegoArcos14|                   544915|   false|\n",
      "|    TVCDeportes|                   543095|   false|\n",
      "|       EP_Mundo|                   538525|   false|\n",
      "|         LALATE|                   516153|   false|\n",
      "|  piercearrow33|                   503015|   false|\n",
      "+---------------+-------------------------+--------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "    SELECT user.screen_name, max(user.followers_count), user.verified\n",
    "    FROM tweets\n",
    "    WHERE user.verified == false\n",
    "    GROUP BY user.verified,user.screen_name\n",
    "    ORDER BY max(user.followers_count) DESC\n",
    "\"\"\").show(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daminous_Purity has the highest followers count in unverified users with 998742 followers while piercearrow33 is in the 12th place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used user.verified in where condition here to check whether the user if verified or not and grouping by followers count, screen_name and verified. Then we have used order by followers_count in descending order to get the top most count of the followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 - Analyze common words in tweet text\n",
    "\n",
    "Following the example in class, use `tweets.rdd` to find the most common interesting words in tweet text.  To keep it \"interesting\", remove at least 12 common stop words found in tweets, like \"a\", \"an\", \"the\", and \"RT\" (you might want to derive these stop words from initial results).  A simple split on text whitespace like we had in class is sufficient; you do not have to account for punctuation. \n",
    "\n",
    "After you find the most common words, use dataframe or SQL queries to find patterns among how those words are used.  For example, are they more frequently used by Dodgers or Astros fans, or by people in one part of the country over another?  Explore and see what you can find, and discuss your findings.\n",
    "\n",
    "You will notice that common words include words like \"thisteam\" and \"earnhistory\". I would like you to write two queries to investigate whether those two words are used by the Astros or Dodgers\n",
    "\n",
    "Hint: don't forget all the word count pipeline steps we used earlier in class.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('RT', 115635),\n",
       " ('the', 78439),\n",
       " ('a', 34723),\n",
       " ('Astros', 33868),\n",
       " ('to', 33352),\n",
       " ('', 29647),\n",
       " ('in', 29533),\n",
       " ('@astros:', 29038),\n",
       " ('Dodgers', 24360),\n",
       " ('#WorldSeries', 24328),\n",
       " ('for', 20991),\n",
       " ('@astros', 18166),\n",
       " ('of', 17664),\n",
       " ('is', 17099),\n",
       " ('I', 16248),\n",
       " ('and', 15898),\n",
       " ('this', 15561),\n",
       " ('The', 14733),\n",
       " ('#EarnHistory', 14305),\n",
       " ('#Astros', 14012),\n",
       " ('@Dodgers', 13856),\n",
       " ('game', 13295),\n",
       " ('win', 11522),\n",
       " ('on', 10849),\n",
       " ('@Dodgers:', 10090),\n",
       " ('are', 9689),\n",
       " ('it', 9623),\n",
       " ('that', 9538),\n",
       " ('#Dodgers', 9311),\n",
       " ('World', 8715),\n",
       " ('THE', 8522),\n",
       " ('you', 8505),\n",
       " ('A', 8259),\n",
       " ('de', 7749),\n",
       " ('was', 7727),\n",
       " ('Game', 7428),\n",
       " ('Series', 7404),\n",
       " ('have', 7090),\n",
       " ('just', 7049),\n",
       " ('This', 6968),\n",
       " ('5', 6939),\n",
       " ('one', 6770),\n",
       " ('#ThisTeam', 6436),\n",
       " ('with', 6356),\n",
       " (\"LET'S\", 6285),\n",
       " ('GAME', 6279),\n",
       " ('out', 6076),\n",
       " ('dodgers', 6042),\n",
       " ('go', 6030),\n",
       " ('TIE', 5986)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_top = tweets.rdd.flatMap(lambda r: r['text'].split(' ')) \\\n",
    "        .map(lambda t: (t, 1)) \\\n",
    "        .reduceByKey(lambda a, b: a + b) \\\n",
    "        .takeOrdered(50, key=lambda pair: -pair[1])\n",
    "rdd_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above query is to get the top 50 frequent words used by the users and we can see how many times each word is used in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Astros', 33868),\n",
       " ('@astros:', 29038),\n",
       " ('Dodgers', 24360),\n",
       " ('#WorldSeries', 24328),\n",
       " ('@astros', 18166),\n",
       " ('#EarnHistory', 14305),\n",
       " ('#Astros', 14012),\n",
       " ('@Dodgers', 13856),\n",
       " ('game', 13295),\n",
       " ('win', 11522),\n",
       " ('@Dodgers:', 10090),\n",
       " ('#Dodgers', 9311),\n",
       " ('World', 8715),\n",
       " ('de', 7749),\n",
       " ('Game', 7428),\n",
       " ('Series', 7404),\n",
       " ('just', 7049),\n",
       " ('one', 6770),\n",
       " ('#ThisTeam', 6436),\n",
       " ('with', 6356)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [\"a\", \"is\", \"the\", \"rt\", \"and\", \"to\", \"of\", \"in\", \"for\", \"i\", \"this\", \"The\", \"\", \"on\", \"are\", \"it\", \"you\", \"was\", \"have\", \"that\", \"5\"]  \n",
    "\n",
    "result=tweets.rdd.flatMap(lambda r: r['text'].split(' ')) \\\n",
    "    .filter(lambda t: t.lower() not in stop_words) \\\n",
    "    .map(lambda t: (t, 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .takeOrdered(20, key=lambda pair: -pair[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined some stop words using the result from previous query and filtered out/removed those from the frequent commmon words and displayed the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|      Astros|33868|\n",
      "|    @astros:|29038|\n",
      "|     Dodgers|24360|\n",
      "|#WorldSeries|24328|\n",
      "|     @astros|18166|\n",
      "|#EarnHistory|14305|\n",
      "|     #Astros|14012|\n",
      "|    @Dodgers|13856|\n",
      "|        game|13295|\n",
      "|         win|11522|\n",
      "|   @Dodgers:|10090|\n",
      "|    #Dodgers| 9311|\n",
      "|       World| 8715|\n",
      "|          de| 7749|\n",
      "|        Game| 7428|\n",
      "|      Series| 7404|\n",
      "|        just| 7049|\n",
      "|         one| 6770|\n",
      "|   #ThisTeam| 6436|\n",
      "|        with| 6356|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df = sqlc.createDataFrame(result, [\"word\", \"count\"])\n",
    "tweets_df.show()\n",
    "\n",
    "tweets_df.createOrReplaceTempView(\"tweets_words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have converted the list into a dataframe and then to a view to use it in the following query as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|     Dodgers|67403|\n",
      "|    @Dodgers|26897|\n",
      "|       World|21872|\n",
      "|      Series|21395|\n",
      "|      Astros|18249|\n",
      "|#WorldSeries|17443|\n",
      "|          de|12925|\n",
      "|    #Dodgers|10619|\n",
      "|   #ThisTeam|10405|\n",
      "|   @Dodgers:|10093|\n",
      "|        game| 8202|\n",
      "|        Game| 5649|\n",
      "|         win| 5375|\n",
      "|         one| 4631|\n",
      "|     #Astros| 4408|\n",
      "|     @astros| 4384|\n",
      "|        with| 3139|\n",
      "|        just| 2056|\n",
      "|#EarnHistory| 1110|\n",
      "|    @astros:|  178|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dodgers_words = sqlc.sql(\"\"\"\n",
    "    SELECT w.word, COUNT(w.word) as count\n",
    "    FROM tweets t\n",
    "    JOIN tweets_words w ON t.text LIKE ('%' || w.word || '%')\n",
    "    WHERE lower(t.text) LIKE '%dodgers%' \n",
    "    GROUP BY w.word\n",
    "    ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "dodgers_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|      Astros|63814|\n",
      "|     @astros|50283|\n",
      "|    @astros:|29044|\n",
      "|       World|26983|\n",
      "|      Series|26650|\n",
      "|     Dodgers|21902|\n",
      "|#EarnHistory|20479|\n",
      "|#WorldSeries|19531|\n",
      "|          de|16065|\n",
      "|     #Astros|15905|\n",
      "|        game|15249|\n",
      "|         win|15095|\n",
      "|        Game| 8955|\n",
      "|         one| 8918|\n",
      "|        just| 5821|\n",
      "|    @Dodgers| 5253|\n",
      "|        with| 4897|\n",
      "|    #Dodgers| 4693|\n",
      "|   #ThisTeam| 1202|\n",
      "|   @Dodgers:|  356|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "astros_words = sqlc.sql(\"\"\"\n",
    "    SELECT w.word, COUNT(w.word) as count\n",
    "    FROM tweets t\n",
    "    JOIN tweets_words w ON t.text LIKE ('%' || w.word || '%')\n",
    "    WHERE lower(t.text) LIKE '%astros%' \n",
    "    GROUP BY w.word\n",
    "    ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "astros_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above two queries, we joined tables tweets and created table tweets_words and with conditions to check for astros or dodgers. It gave us the count of words where the words are seen along with dodgers or astros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  423|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thisteam_dodgers_result = sqlc.sql(\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM tweets\n",
    "    WHERE text LIKE '%thisteam%'\n",
    "    AND lower(text) LIKE '%dodgers%' AND LOWER(text) NOT LIKE '%astros%'\n",
    "\"\"\")\n",
    "\n",
    "thisteam_dodgers_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|   20|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thisteam_astros_result = sqlc.sql(\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM tweets\n",
    "    WHERE text LIKE '%thisteam%'\n",
    "    AND lower(text) LIKE '%astros%' AND LOWER(text) NOT LIKE '%dodgers%'\n",
    "\"\"\")\n",
    "\n",
    "thisteam_astros_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two queries, we can say that dodgers are most likely to use the word thisteam in their tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  149|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "earnhistory_dodgers_result = sqlc.sql(\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM tweets\n",
    "    WHERE text LIKE '%EarnHistory%'\n",
    "    AND lower(text) LIKE '%dodgers%' AND LOWER(text) NOT LIKE '%astros%'\n",
    "\"\"\")\n",
    "\n",
    "earnhistory_dodgers_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|19524|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "earnhistory_astros_result = sqlc.sql(\"\"\"\n",
    "    SELECT COUNT(*) as count\n",
    "    FROM tweets\n",
    "    WHERE text LIKE '%EarnHistory%'\n",
    "    AND lower(text) LIKE '%astros%' AND LOWER(text) NOT LIKE '%dodgers%'\n",
    "\"\"\")\n",
    "\n",
    "earnhistory_astros_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two tweets, we can say that astros clearly are using the word earnhistory in their tweets more than the dodgers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
